<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white" alt="FastAPI">
  <img src="https://img.shields.io/badge/CUDA-12.0+-76B900?style=for-the-badge&logo=nvidia&logoColor=white" alt="CUDA">
  <img src="https://img.shields.io/badge/LLM-Qwen2.5--32B-FF6F00?style=for-the-badge" alt="LLM">
  <img src="https://img.shields.io/badge/YOLOv8-Computer%20Vision-00FFFF?style=for-the-badge" alt="YOLOv8">
</p>

<h1 align="center">üöó Automobile Assistant AI</h1>

<p align="center">
  <strong>An intelligent French-language automobile technical assistant powered by state-of-the-art AI</strong>
</p>

<p align="center">
  <a href="#-features">Features</a> ‚Ä¢
  <a href="#-architecture">Architecture</a> ‚Ä¢
  <a href="#-requirements">Requirements</a> ‚Ä¢
  <a href="#-installation">Installation</a> ‚Ä¢
  <a href="#-api-reference">API Reference</a> ‚Ä¢
  <a href="#-usage">Usage</a>
</p>

---

## üåü Overview

**Automobile Assistant AI** is a production-ready FastAPI application designed for the **KOUNHANY** platform - a Moroccan automotive aftermarket service. It combines a powerful 32-billion parameter language model with computer vision capabilities to provide:

- üí¨ **Intelligent Conversations** - Natural French-language dialogue about automotive topics
- üîç **Dashboard Detection** - AI-powered recognition of 68 different dashboard warning indicators
- üîß **OBD-II Diagnostics** - Instant lookup of 500+ diagnostic trouble codes
- üìä **Analytics & Learning** - Continuous improvement through conversation analysis
- üåê **Web Search Integration** - Real-time information retrieval for current data

---

## ‚ú® Features

### ü§ñ Large Language Model
- **Model**: Qwen2.5-32B-Instruct (Q5_K_M quantization)
- **Parameters**: 32 Billion
- **Context Window**: 4,096 tokens
- **Specialization**: French automotive technical assistance
- **Anti-hallucination**: Strict prompting to prevent fabricated information

### üëÅÔ∏è Computer Vision
- **Model**: YOLOv8 Custom-trained
- **Classes**: 68 dashboard warning indicators
- **Accuracy**: High-confidence detection (>30% threshold)
- **Input**: Base64-encoded images (JPG, PNG)

### üîß OBD-II Database
- **Coverage**: 500+ diagnostic codes
- **Categories**: P (Powertrain), B (Body), C (Chassis), U (Network)
- **Information**: French descriptions, severity levels, causes, solutions
- **Response Time**: <100ms (instant lookup)

### üìù Smart Features
- **Typo Correction**: Fuzzy matching for misspelled words (like ChatGPT)
- **Conversation Memory**: Per-user context retention (last 4 exchanges)
- **Intent Detection**: Automatic categorization of queries
- **Response Cleaning**: Removes system prompt leaks and artifacts

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        User Request                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ   FastAPI Endpoint    ‚îÇ
                ‚îÇ      /chat (POST)     ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ                               ‚îÇ
            ‚ñº                               ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Text Input  ‚îÇ              ‚îÇ   Image Input    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                               ‚îÇ
           ‚ñº                               ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Typo Correction ‚îÇ          ‚îÇ  YOLOv8 Detection  ‚îÇ
    ‚îÇ  (RapidFuzz)     ‚îÇ          ‚îÇ  (68 Classes)      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                               ‚îÇ
           ‚ñº                               ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ
    ‚îÇ  OBD Code Check  ‚îÇ                   ‚îÇ
    ‚îÇ  (500+ Codes)    ‚îÇ                   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
           ‚îÇ                               ‚îÇ
           ‚ñº                               ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
    ‚îÇ Conversation Memory     ‚îÇ           ‚îÇ
    ‚îÇ (Per User Context)      ‚îÇ           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
           ‚îÇ                               ‚îÇ
           ‚ñº                               ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
    ‚îÇ   Qwen2.5-32B-Instruct  ‚îÇ           ‚îÇ
    ‚îÇ   ‚Ä¢ GPU: RTX 4090       ‚îÇ           ‚îÇ
    ‚îÇ   ‚Ä¢ VRAM: 23GB/24GB     ‚îÇ           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
           ‚îÇ                               ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ    JSON Response     ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üíª Requirements

### Hardware Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **GPU** | RTX 3090 (24GB) | **RTX 4090 (24GB)** |
| **VRAM** | 24GB | 24GB |
| **RAM** | 32GB | 64GB |
| **Storage** | 50GB SSD | 100GB NVMe SSD |
| **CPU** | 8 cores | 16+ cores |

> ‚ö†Ô∏è **Important**: This project requires a **24GB VRAM GPU** (RTX 3090/4090 or equivalent). The Qwen2.5-32B model uses approximately **23GB VRAM** during inference.

### Software Requirements

- **OS**: Ubuntu 20.04+ / Debian 11+
- **Python**: 3.10+
- **CUDA**: 12.0+
- **cuDNN**: 8.0+
- **Driver**: NVIDIA 525.0+

---

## üöÄ Installation

### Step 1: Clone the Repository

```bash
git clone https://github.com/youssefhajaj/automobile-assistant-ai.git
cd automobile-assistant-ai
```

### Step 2: Set Up Python Environment

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate  # Windows

# Upgrade pip
pip install --upgrade pip
```

### Step 3: Install Dependencies

```bash
# Core dependencies
pip install fastapi uvicorn pydantic pillow numpy jinja2

# Machine Learning
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install ultralytics opencv-python

# LLM with CUDA support
pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121

# Additional features
pip install rapidfuzz python-docx
```

### Step 4: Download the LLM Model

```bash
# Install huggingface-cli if not already installed
pip install huggingface_hub

# Login to HuggingFace (optional, for gated models)
huggingface-cli login

# Download Qwen2.5-32B-Instruct (Q5_K_M quantization - 22GB)
huggingface-cli download Qwen/Qwen2.5-32B-Instruct-GGUF \
    qwen2.5-32b-instruct-q5_k_m.gguf \
    --local-dir . \
    --local-dir-use-symlinks False

# Rename to expected filename
mv qwen2.5-32b-instruct-q5_k_m.gguf Qwen2.5-32B-Instruct-Q5_K_M.gguf
```

### Step 5: Configure GPU (CUDA)

```bash
# Verify CUDA installation
nvidia-smi

# Expected output should show:
# - Driver Version: 525.0+
# - CUDA Version: 12.0+
# - GPU: RTX 4090 or equivalent with 24GB VRAM

# Test PyTorch CUDA
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0)}')"
```

### Step 6: Start the Server

```bash
# Development mode
uvicorn api_server:app --host 0.0.0.0 --port 8000 --reload

# Production mode (background)
nohup uvicorn api_server:app --host 0.0.0.0 --port 8000 > api.log 2>&1 &

# Check logs
tail -f api.log
```

### Step 7: Verify Installation

```bash
# Health check
curl http://localhost:8000/

# Expected response:
# {"message":"API is running","status":"healthy"}

# Detailed health check
curl http://localhost:8000/health
```

---

## üì° API Reference

### Base URL
```
http://your-server-ip:8000
```

### Endpoints

#### `GET /` - Health Check
```bash
curl http://localhost:8000/
```
**Response:**
```json
{
  "message": "API is running",
  "status": "healthy"
}
```

---

#### `POST /chat` - Main Chat Endpoint

**Text Request:**
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "unique_user_id",
    "content_type": "text",
    "timestamp": "2025-01-01T12:00:00.000000Z",
    "data": {
      "text": "Bonjour, comment changer l'\''huile moteur?"
    }
  }'
```

**Text Response:**
```json
{
  "status": "success",
  "code": 200,
  "message": "Text processed successfully.",
  "data": {
    "response_text": "Bonjour ! Pour changer l'huile moteur, voici les √©tapes..."
  },
  "timestamp": "2025-01-01T12:00:05.123456"
}
```

**Image Request:**
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "unique_user_id",
    "content_type": "image",
    "timestamp": "2025-01-01T12:00:00.000000Z",
    "data": {
      "media": {
        "format": "jpg",
        "data": "BASE64_ENCODED_IMAGE_STRING"
      }
    }
  }'
```

**Image Response:**
```json
{
  "status": "success",
  "code": 200,
  "message": "Image processed successfully.",
  "data": {
    "response_text": "üöó **INDICATEURS D√âTECT√âS:**\n‚Ä¢ check_engine (95.2%)\n‚Ä¢ oil_pressure (87.3%)",
    "detection_data": {
      "detections": [
        {"class": "check_engine", "confidence": 0.952},
        {"class": "oil_pressure", "confidence": 0.873}
      ],
      "total": 2
    }
  }
}
```

---

#### `GET /obd/{code}` - OBD-II Code Lookup

```bash
curl http://localhost:8000/obd/P0420
```

**Response:**
```json
{
  "code": "P0420",
  "description_en": "Catalyst System Efficiency Below Threshold (Bank 1)",
  "description_fr": "Efficacit√© du catalyseur en dessous du seuil (Banc 1)",
  "severity": "medium",
  "cause": "Catalyseur us√© ou d√©fectueux, sonde lambda d√©faillante",
  "solution": "V√©rifier les sondes lambda, remplacer le catalyseur si n√©cessaire"
}
```

---

#### `GET /chat-page` - Web Interface

Access the built-in chat interface at:
```
http://localhost:8000/chat-page
```

---

#### `GET /analytics` - Usage Analytics

```bash
curl http://localhost:8000/analytics
```

---

#### `DELETE /conversation/{user_id}` - Clear Conversation History

```bash
curl -X DELETE http://localhost:8000/conversation/user123
```

---

## üéØ Usage

### Web Interface

1. Navigate to `http://your-server:8000/chat-page`
2. Type your question in French
3. Click send or press Enter
4. For dashboard images, click the camera icon to upload

### Mobile Integration

```python
import requests

# Text query
response = requests.post(
    "http://your-server:8000/chat",
    json={
        "user_id": "mobile_user_123",
        "content_type": "text",
        "timestamp": "2025-01-01T12:00:00.000000Z",
        "data": {"text": "Que signifie le voyant moteur?"}
    }
)
print(response.json())
```

### OBD-II Quick Lookup

```bash
# In chat, just type the code:
"P0420"
"Mon code erreur est C0035"
"J'ai eu le code U0100"
```

---

## üîß Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `MODEL_PATH` | Path to GGUF model | `./Qwen2.5-32B-Instruct-Q5_K_M.gguf` |
| `YOLO_MODEL` | Path to YOLOv8 model | `./best.pt` |
| `N_GPU_LAYERS` | GPU layers (-1 = all) | `-1` |
| `N_CTX` | Context window size | `4096` |
| `PORT` | Server port | `8000` |

### Model Parameters (in `api_server.py`)

```python
model = Llama(
    model_path="Qwen2.5-32B-Instruct-Q5_K_M.gguf",
    n_gpu_layers=-1,      # All layers on GPU
    n_ctx=4096,           # Context window
    n_batch=256,          # Batch size
    n_threads=32,         # CPU threads
    n_threads_batch=32,
    verbose=False
)
```

### Inference Parameters

```python
response = model(
    prompt,
    max_tokens=200,       # Maximum response length
    temperature=0.3,      # Lower = more focused
    top_p=0.9,
    repeat_penalty=1.15,
    stop=["<|im_end|>", "<|im_start|>"]
)
```

---

## üìä Performance

| Metric | Value |
|--------|-------|
| **Text Response Time** | 2-4 seconds |
| **Image Detection Time** | 1-2 seconds |
| **OBD Code Lookup** | <100ms |
| **GPU Memory Usage** | 23GB / 24GB |
| **Concurrent Users** | 10-20 (recommended) |

---

## üóÇÔ∏è Project Structure

```
automobile-assistant-ai/
‚îú‚îÄ‚îÄ api_server.py          # Main FastAPI application
‚îú‚îÄ‚îÄ keywords.py            # French automotive keywords
‚îú‚îÄ‚îÄ obd_codes.py           # OBD-II diagnostic codes database
‚îú‚îÄ‚îÄ analytics.py           # Analytics & learning system
‚îú‚îÄ‚îÄ web_search.py          # DuckDuckGo integration
‚îú‚îÄ‚îÄ best.pt                # YOLOv8 model (68 classes)
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ chat.html          # Web interface
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

## üõ°Ô∏è Security Notes

- Never commit API keys or tokens to the repository
- Use environment variables for sensitive configuration
- The analytics database contains user conversations - handle appropriately
- Implement rate limiting for production deployments

---

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## üìÑ License

This project is proprietary software developed for KOUNHANY.

---

## üë®‚Äçüíª Author

**Youssef Hajaj**

---

<p align="center">
  <strong>Built with ‚ù§Ô∏è for the Moroccan automotive community</strong>
</p>
